# Apply-Lightweight-Fine-Tuning-to-a-Foundation-Model

This project demonstrates how to perform parameter-efficient fine-tuning (PEFT) using the Low-Rank Adaptation (LoRA) technique with the Hugging Face Transformers library. The example uses the distilbert-base-uncased model and the IMDB dataset for sentiment analysis.
